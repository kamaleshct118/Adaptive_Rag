{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üè• Adaptive Learning Assistant for Rational Antibiotic Use & AMR\n",
                "\n",
                "## üìã Overview\n",
                "This notebook contains the complete, verified implementation of the **Basic Adaptive RAG Architecture** for Antimicrobial Stewardship. \n",
                "\n",
                "It is designed to strictly follow the **\"Single Query Restructure\"** workflow, ensuring all feedback loops (Retrieval Failure, Irrelevance) return to a single central logic node for correction.\n",
                "\n",
                "## üö® Safety & Scope Disclaimer\n",
                "- **Educational Only**: This system explains mechanisms and guidelines. It does NOT diagnose or treat.\n",
                "- **No Prescriptions**: The model is strictly prohibited from suggesting dosages or specific treatments for a patient.\n",
                "- **Source of Truth**: Answers are grounded *only* in the retrieved vector context.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üèóÔ∏è Architecture & Pipeline Flow\n",
                "\n",
                "The code below implements the following STRICT logic flow:\n",
                "\n",
                "1.  **START**: User Query.\n",
                "2.  **üß© NODE 1: Query Analysis & Restructuring (Central Control)**\n",
                "    - *Action*: Check Relevance, Identify Category, Restructure Query, Set Tone.\n",
                "    - *Decision*: If Not Relevant ‚ûî **STOP**.\n",
                "3.  **üî¢ Embedding**: Convert `Restructured Query` to Vector.\n",
                "4.  **üå≤ Retrieval**: Fetch Top-K Contexts from Pinecone.\n",
                "5.  **‚öñÔ∏è NODE 2: Retrieval Grader**\n",
                "    - *Action*: Check if context supports the query.\n",
                "    - *Loop*: If **BAD** ‚ûî **GO TO NODE 1 (Restructure Query)**.\n",
                "6.  **‚úçÔ∏è NODE 3: Answer Generator**\n",
                "    - *Action*: Generate answer using *only* context, adhering to Category & Tone.\n",
                "7.  **üõ°Ô∏è NODE 4: Hallucination Checker**\n",
                "    - *Action*: Verify answer against context.\n",
                "    - *Loop*: If **YES (Hallucinated)** ‚ûî **REGENERATE ANSWER (Local Loop)**.\n",
                "8.  **üéØ NODE 5: Relevance Checker**\n",
                "    - *Action*: Verify answer addresses Original User Query.\n",
                "    - *Loop*: If **NO (Not Relevant)** ‚ûî **GO TO NODE 1 (Restructure Query)**.\n",
                "9.  **üèÅ END**: Final Verified Answer."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "--- \n",
                "### üü¢ Cell 1: Library Installation\n",
                "**Purpose**: Install all required Python packages for the pipeline.\n",
                "- `pinecone-client`: for Vector DB connection.\n",
                "- `gradio`: for the chat interface.\n",
                "- `sentence-transformers`: for local query embedding.\n",
                "- `requests`: for API calls to the LLM."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install pinecone-client gradio numpy requests sentence-transformers"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üü¢ Cell 2: LLM Connection Setup\n",
                "**Purpose**: Configure the connection to the LLaMA-70B model.\n",
                "We use a `call_llm` wrapper function to handle all prompt interactions consistently."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import requests\n",
                "import json\n",
                "\n",
                "# üîë USER INPUT: API Credentials\n",
                "API_KEY = \"\" # @param {type:\"string\"}\n",
                "BASE_URL = \"https://api.groq.com/openai/v1\" # @param {type:\"string\"}\n",
                "\n",
                "# üß† MODEL: LLaMA 70B (Strict Requirement)\n",
                "MODEL_NAME = \"llama-3.3-70b-versatile\"\n",
                "\n",
                "def call_llm(messages, temperature=0.3):\n",
                "    \"\"\"\n",
                "    Sends a message list to the LLM and returns the text response.\n",
                "    Handles errors gracefully.\n",
                "    \"\"\"\n",
                "    if not API_KEY:\n",
                "        return \"‚ùå Error: API Key is missing. Please set it in Cell 2.\"\n",
                "\n",
                "    headers = {\n",
                "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
                "        \"Content-Type\": \"application/json\"\n",
                "    }\n",
                "    payload = {\n",
                "        \"model\": MODEL_NAME,\n",
                "        \"messages\": messages,\n",
                "        \"temperature\": temperature\n",
                "    }\n",
                "    \n",
                "    try:\n",
                "        response = requests.post(f\"{BASE_URL}/chat/completions\", headers=headers, json=payload)\n",
                "        response.raise_for_status()\n",
                "        return response.json()['choices'][0]['message']['content']\n",
                "    except Exception as e:\n",
                "        print(f\"‚ùå LLM Call Failed: {e}\")\n",
                "        return None"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üü¢ Cell 3: Pinecone Configuration\n",
                "**Purpose**: Initialize the connection to your specific Pinecone Index.\n",
                "**Assumption**: The index `PINECONE_INDEX_NAME` already exists and contains your embedded medical documents."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pinecone import Pinecone\n",
                "\n",
                "# üå≤ PINECONE CREDENTIALS\n",
                "PINECONE_API_KEY = \"\" # @param {type:\"string\"}\n",
                "PINECONE_INDEX_NAME = \"\" # @param {type:\"string\"}\n",
                "\n",
                "# Initialize Client\n",
                "try:\n",
                "    if PINECONE_API_KEY:\n",
                "        pc = Pinecone(api_key=PINECONE_API_KEY)\n",
                "        index = pc.Index(PINECONE_INDEX_NAME)\n",
                "        print(f\"‚úÖ Successfully connected to Pinecone Index: {PINECONE_INDEX_NAME}\")\n",
                "    else:\n",
                "        print(\"‚ö†Ô∏è Warning: PINECONE_API_KEY not set. Retrieval will be simulated.\")\n",
                "        index = None\n",
                "except Exception as e:\n",
                "    print(f\"‚ùå Pinecone Connection Error: {e}\")\n",
                "    index = None"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üü¢ Cell 4: Embedding Function\n",
                "**Purpose**: Convert the *Restructured Query* into a vector for searching.\n",
                "We use `sentence-transformers/all-MiniLM-L6-v2` locally. In a production sync, this must match your document embedding model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sentence_transformers import SentenceTransformer\n",
                "\n",
                "# Load Model\n",
                "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
                "\n",
                "def get_query_embedding(text):\n",
                "    \"\"\"\n",
                "    Generates a vector embedding for the input text.\n",
                "    \"\"\"\n",
                "    if not text: return []\n",
                "    return embedder.encode(text).tolist()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "--- \n",
                "## ü§ñ Agent Logic Modules\n",
                "The following cells implement the individual \"Brain Nodes\" of the architecture.\n",
                "\n",
                "### üü¢ Cell 5: Query Analysis & Restructuring Node (The Central Node)\n",
                "**Role**: The Orchestrator calls this first. It checks relevance and rewrites the query.\n",
                "**Feedback Logic**: It accepts a `feedback_reason` (optional). If provided, it knows the previous attempt failed and re-writes the query accordingly."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def agent_analyze_query(user_query, feedback_reason=None):\n",
                "    \"\"\"\n",
                "    Analyzes the user query. \n",
                "    If feedback_reason is present, it uses that to improve the restructured query.\n",
                "    \"\"\"\n",
                "\n",
                "    # üìù SYSTEM PROMPT\n",
                "    system_prompt = \"\"\"\n",
                "You are a medical learning query analyzer.\n",
                "\n",
                "Tasks:\n",
                "1. Determine if the query is relevant to antibiotic use or antimicrobial resistance (AMR).\n",
                "2. Classify the query into ONE category:\n",
                "   - Infection Context Explanation\n",
                "   - Antibiotic Class Reasoning\n",
                "   - Resistance Mechanism\n",
                "   - Stewardship Principle\n",
                "   - Safety / Adverse Effects\n",
                "   - Guideline Explanation\n",
                "3. Rewrite the query to optimize retrieval for a vector database.\n",
                "4. Decide the appropriate answer tone (Simplified educational vs Structured clinical).\n",
                "\n",
                "STRICT Output Format:\n",
                "CATEGORY: [Category Name]\n",
                "RESTRUCTURED_QUERY: [New Query]\n",
                "ANSWER_TONE: [Tone]\n",
                "\n",
                "If NOT relevant to antibiotics/AMR:\n",
                "Output: NOT_RELEVANT\n",
                "    \"\"\"\n",
                "\n",
                "    # üîÑ Dynamic User Prompt based on Loop State\n",
                "    if feedback_reason:\n",
                "        user_content = f\"User Query: {user_query}\\n\\n‚ö†Ô∏è PREVIOUS FAILURE: {feedback_reason}.\\nACTION: You MUST rewrite the query differently to address this failure.\"\n",
                "    else:\n",
                "        user_content = f\"User Query: {user_query}\"\n",
                "\n",
                "    # Call LLM\n",
                "    messages = [\n",
                "        {\"role\": \"system\", \"content\": system_prompt},\n",
                "        {\"role\": \"user\", \"content\": user_content}\n",
                "    ]\n",
                "    response = call_llm(messages)\n",
                "\n",
                "    # üß† Parsing Logic\n",
                "    result = {\n",
                "        \"is_relevant\": True,\n",
                "        \"category\": \"General\",\n",
                "        \"restructured_query\": user_query,\n",
                "        \"tone\": \"Educational\"\n",
                "    }\n",
                "\n",
                "    if \"NOT_RELEVANT\" in response:\n",
                "        result[\"is_relevant\": False]\n",
                "        return result\n",
                "\n",
                "    # Simple parsing of the strict keys\n",
                "    lines = response.split('\\n')\n",
                "    for line in lines:\n",
                "        if line.startswith(\"CATEGORY:\"):\n",
                "            result[\"category\"] = line.replace(\"CATEGORY:\", \"\").strip()\n",
                "        elif line.startswith(\"RESTRUCTURED_QUERY:\"):\n",
                "            result[\"restructured_query\"] = line.replace(\"RESTRUCTURED_QUERY:\", \"\").strip()\n",
                "        elif line.startswith(\"ANSWER_TONE:\"):\n",
                "            result[\"tone\"] = line.replace(\"ANSWER_TONE:\", \"\").strip()\n",
                "\n",
                "    return result"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üü¢ Cell 6: Retrieval Grader Node\n",
                "**Role**: Evaluates if the Context retrieved from Pinecone is actually useful.\n",
                "**Logic**: Returns `GOOD` or `BAD`. If BAD, the Orchestrator will trigger a loop."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def agent_grade_retrieval(query, contexts):\n",
                "    context_str = \"\\n\".join(contexts)\n",
                "    \n",
                "    prompt = f\"\"\"\n",
                "    User Query: {query}\n",
                "    Retrieved Context: {context_str}\n",
                "    \n",
                "    Task: Is the context relevant and sufficient to answer the query?\n",
                "    Output: Answer ONLY 'GOOD' or 'BAD'.\n",
                "    \"\"\"\n",
                "    \n",
                "    response = call_llm([{\"role\": \"user\", \"content\": prompt}])\n",
                "    # Safety fallback\n",
                "    if not response: return \"BAD\"\n",
                "    \n",
                "    return \"BAD\" if \"BAD\" in response.upper() else \"GOOD\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üü¢ Cell 7: Answer Generator Node\n",
                "**Role**: Synthesizes the final answer using *only* the context."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def agent_generate_answer(query, contexts, category, tone):\n",
                "    context_str = \"\\n\".join(contexts)\n",
                "    \n",
                "    system_prompt = f\"\"\"\n",
                "You are an educational medical assistant.\n",
                "Use ONLY the provided context.\n",
                "Follow the answer tone: {tone} and category: {category} strictly.\n",
                "\n",
                "Category-specific guidance:\n",
                "- Infection context ‚Üí general principles\n",
                "- Antibiotic class ‚Üí spectrum & resistance risks\n",
                "- Resistance mechanism ‚Üí biological explanation\n",
                "- Stewardship ‚Üí safety & AMR prevention\n",
                "- Safety ‚Üí adverse effects & caution\n",
                "- Guidelines ‚Üí rationale, not instructions\n",
                "\n",
                "Constraints:\n",
                "- No prescribing\n",
                "- No recommendations\n",
                "- Use cautious language\n",
                "    \"\"\"\n",
                "    messages = [\n",
                "        {\"role\": \"system\", \"content\": system_prompt},\n",
                "        {\"role\": \"user\", \"content\": f\"Context: {context_str}\\n\\nQuestion: {query}\"}\n",
                "    ]\n",
                "    \n",
                "    return call_llm(messages)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üü¢ Cell 8: Hallucination Checker Node\n",
                "**Role**: Ensures safety. Checks if the answer contains claims *not* in the source text.\n",
                "**Logic**: Returns `YES` (it is hallucinated) or `NO` (it is safe)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def agent_check_hallucination(answer, contexts):\n",
                "    context_str = \"\\n\".join(contexts)\n",
                "    prompt = f\"\"\"\n",
                "    Context: {context_str}\n",
                "    Generated Answer: {answer}\n",
                "    \n",
                "    Does the answer contain any claim NOT supported by the retrieved context?\n",
                "    Output: Answer ONLY 'YES' or 'NO'.\n",
                "    \"\"\"\n",
                "    response = call_llm([{\"role\": \"user\", \"content\": prompt}])\n",
                "    if not response: return \"NO\" # Assume safe if check fails to prevent blocking\n",
                "    return \"YES\" if \"YES\" in response.upper() else \"NO\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üü¢ Cell 9: Relevance Checker Node\n",
                "**Role**: Ensures the answer actually helps the user.\n",
                "**Logic**: Returns `YES` (Relevant) or `NO` (Not Relevant)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def agent_check_relevance(answer, original_query):\n",
                "    prompt = f\"\"\"\n",
                "    Original Query: {original_query}\n",
                "    Generated Answer: {answer}\n",
                "    \n",
                "    Does the answer fully and clearly address the original query regarding AMR?\n",
                "    Output: Answer ONLY 'YES' or 'NO'.\n",
                "    \"\"\"\n",
                "    response = call_llm([{\"role\": \"user\", \"content\": prompt}])\n",
                "    if not response: return \"YES\"\n",
                "    return \"YES\" if \"YES\" in response.upper() else \"NO\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "--- \n",
                "## ‚öôÔ∏è Orchestrator (The Main Pipeline)\n",
                "\n",
                "### üü¢ Cell 10: The Workflow Control Loop\n",
                "This function ties everything together. It implements the **While Loop** that allows the system to self-correct.\n",
                "\n",
                "**Feedback Logic map:**\n",
                "1. `Retrieval == BAD` ‚ûî Loop back to `agent_analyze_query` (Step 1).\n",
                "2. `Hallucination == YES` ‚ûî Loop back to `agent_generate_answer` (Step 5) *locally*.\n",
                "3. `Relevance == NO` ‚ûî Loop back to `agent_analyze_query` (Step 1)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def adaptive_rag_orchestrator(user_query):\n",
                "    MAX_RETRIES = 3\n",
                "    attempt = 0\n",
                "    logs = []\n",
                "    \n",
                "    # Holds feedback for the next loop iteration (if needed)\n",
                "    feedback_reason = None\n",
                "    \n",
                "    while attempt < MAX_RETRIES:\n",
                "        attempt += 1\n",
                "        logs.append(f\"\\n--- üîÑ Cycle {attempt} Start ---\")\n",
                "        \n",
                "        # --- STEP 1: ANALYSIS ---\n",
                "        analysis = agent_analyze_query(user_query, feedback_reason)\n",
                "        \n",
                "        if not analysis[\"is_relevant\"]:\n",
                "            logs.append(\"üõë Stopped: Query identified as Not Relevant.\")\n",
                "            return \"I can only answer questions related to Antimicrobial Stewardship and AMR.\", logs\n",
                "            \n",
                "        restructured_q = analysis[\"restructured_query\"]\n",
                "        category = analysis[\"category\"]\n",
                "        tone = analysis[\"tone\"]\n",
                "        logs.append(f\"üîç Analyzed: Category=[{category}] | New Query=[{restructured_q}]\")\n",
                "        \n",
                "        # --- STEP 2: EMBEDDING ---\n",
                "        vector = get_query_embedding(restructured_q)\n",
                "        \n",
                "        # --- STEP 3: RETRIEVAL ---\n",
                "        if index:\n",
                "            results = index.query(vector=vector, top_k=3, include_metadata=True)\n",
                "            matches = results.get('matches', [])\n",
                "            contexts = [m['metadata']['text'] for m in matches if 'text' in m['metadata']]\n",
                "        else:\n",
                "            # Mock for demo if no DB connected\n",
                "            contexts = [\"[MOCK CONTEXT] Bacteria develop resistance through mutation... Stewardship requires right drug, right dose.\"]\n",
                "\n",
                "        # --- STEP 4: RETRIEVAL GRADING ---\n",
                "        grade = agent_grade_retrieval(restructured_q, contexts)\n",
                "        if grade == \"BAD\":\n",
                "            logs.append(\"‚ö†Ô∏è Retrieval Grader: BAD -> Looping back to Restructure.\")\n",
                "            feedback_reason = \"Previous query yielded poor/irrelevant documents\"\n",
                "            continue # ‚Ü©Ô∏è LOOP TO STEP 1\n",
                "        else:\n",
                "            logs.append(\"‚úÖ Retrieval Grader: GOOD\")\n",
                "            \n",
                "        # --- STEP 5: GENERATION ---\n",
                "        answer = agent_generate_answer(restructured_q, contexts, category, tone)\n",
                "        \n",
                "        # --- STEP 6: VALIDATION GATES ---\n",
                "        \n",
                "        # A. Hallucination Check\n",
                "        is_hallucinated = agent_check_hallucination(answer, contexts)\n",
                "        if is_hallucinated == \"YES\":\n",
                "            logs.append(\"‚ö†Ô∏è Hallucination Detected -> Regenerating (Local correction).\")\n",
                "            # Local retry (one shot)\n",
                "            answer = agent_generate_answer(restructured_q, contexts, category, tone)\n",
                "        \n",
                "        # B. Relevance Check\n",
                "        is_relevant_answer = agent_check_relevance(answer, user_query)\n",
                "        if is_relevant_answer == \"NO\":\n",
                "            logs.append(\"‚ö†Ô∏è Answer Relevance: NO -> Looping back to Restructure.\")\n",
                "            feedback_reason = \"Generated answer did not fully address the user intent\"\n",
                "            continue # ‚Ü©Ô∏è LOOP TO STEP 1\n",
                "            \n",
                "        # ‚úÖ SUCCESS\n",
                "        logs.append(\"‚úÖ Verification Passed: Sending Final Answer.\")\n",
                "        final_output = f\"**Category:** {category}\\n\\n{answer}\"\n",
                "        return final_output, logs\n",
                "\n",
                "    return \"‚ùå Sorry, I tried multiple times but couldn't generate a verified answer. Please try rephrasing.\", logs"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üü¢ Cell 11: Main Interface (Gradio)\n",
                "**Purpose**: Launch the user interface.\n",
                "Run this cell to generate the public or local link."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import gradio as gr\n",
                "\n",
                "def ui_handler(query):\n",
                "    response, logs = adaptive_rag_orchestrator(query)\n",
                "    return response, \"\\n\".join(logs)\n",
                "\n",
                "with gr.Blocks(title=\"Adaptive AMR Assistant\") as demo:\n",
                "    gr.Markdown(\"# üõ°Ô∏è Adaptive AMR Stewardship Assistant\")\n",
                "    gr.Markdown(\"**Educational Tool** | Powered by Adaptive RAG & LLaMA-70B\")\n",
                "    \n",
                "    with gr.Row():\n",
                "        query_input = gr.Textbox(label=\"Enter your question about Antibiotics/AMR\", placeholder=\"e.g., Why avoid Ciprofloxacin in simple UTI?\")\n",
                "        submit_btn = gr.Button(\"Analyze & Search\", variant=\"primary\")\n",
                "    \n",
                "    with gr.Row():\n",
                "        answer_output = gr.Markdown(label=\"Verified Answer\")\n",
                "        log_output = gr.Textbox(label=\"Pipeline Application Logs\", lines=10)\n",
                "        \n",
                "    submit_btn.click(fn=ui_handler, inputs=query_input, outputs=[answer_output, log_output])\n",
                "    \n",
                "demo.launch()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}